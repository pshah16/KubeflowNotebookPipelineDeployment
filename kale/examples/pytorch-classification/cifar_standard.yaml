"apiVersion": |-
  argoproj.io/v1alpha1
"kind": |-
  Workflow
"metadata":
  "annotations":
    "pipelines.kubeflow.org/pipeline_spec": |-
      {"description": "Sequential PyTorch pipeline to train a network on the CIFAR10 dataset", "inputs": [{"default": "2", "name": "TRAIN_STEPS", "optional": true}], "name": "cifar10-classification-gvm3v"}
  "generateName": |-
    cifar10-classification-gvm3v-
"spec":
  "arguments":
    "parameters":
    - "name": |-
        TRAIN_STEPS
      "value": |-
        2
  "entrypoint": |-
    cifar10-classification-gvm3v
  "serviceAccountName": |-
    pipeline-runner
  "templates":
  - "dag":
      "tasks":
      - "arguments":
          "parameters":
          - "name": |-
              TRAIN_STEPS
            "value": |-
              {{inputs.parameters.TRAIN_STEPS}}
          - "name": |-
              kale-marshal-volume-name
            "value": |-
              {{tasks.kale-marshal-volume.outputs.parameters.kale-marshal-volume-name}}
        "dependencies":
        - |-
          kale-marshal-volume
        "name": |-
          dataprocessing
        "template": |-
          dataprocessing
      - "name": |-
          kale-marshal-volume
        "template": |-
          kale-marshal-volume
      - "arguments":
          "parameters":
          - "name": |-
              TRAIN_STEPS
            "value": |-
              {{inputs.parameters.TRAIN_STEPS}}
          - "name": |-
              kale-marshal-volume-name
            "value": |-
              {{tasks.kale-marshal-volume.outputs.parameters.kale-marshal-volume-name}}
        "dependencies":
        - |-
          kale-marshal-volume
        - |-
          train
        "name": |-
          testontest
        "template": |-
          testontest
      - "arguments":
          "parameters":
          - "name": |-
              TRAIN_STEPS
            "value": |-
              {{inputs.parameters.TRAIN_STEPS}}
          - "name": |-
              kale-marshal-volume-name
            "value": |-
              {{tasks.kale-marshal-volume.outputs.parameters.kale-marshal-volume-name}}
        "dependencies":
        - |-
          kale-marshal-volume
        - |-
          testontest
        "name": |-
          testwhole
        "template": |-
          testwhole
      - "arguments":
          "parameters":
          - "name": |-
              TRAIN_STEPS
            "value": |-
              {{inputs.parameters.TRAIN_STEPS}}
          - "name": |-
              kale-marshal-volume-name
            "value": |-
              {{tasks.kale-marshal-volume.outputs.parameters.kale-marshal-volume-name}}
        "dependencies":
        - |-
          dataprocessing
        - |-
          kale-marshal-volume
        "name": |-
          train
        "template": |-
          train
    "inputs":
      "parameters":
      - "name": |-
          TRAIN_STEPS
    "name": |-
      cifar10-classification-gvm3v
  - "container":
      "args":
      - |-
        --TRAIN-STEPS
      - |-
        {{inputs.parameters.TRAIN_STEPS}}
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def dataprocessing(TRAIN_STEPS: int):

            import os
            import shutil
            from kale.utils import pod_utils
            from kale.marshal import resource_save as _kale_resource_save
            from kale.marshal import resource_load as _kale_resource_load

            _kale_data_directory = "/marshal"

            if not os.path.isdir(_kale_data_directory):
                os.makedirs(_kale_data_directory, exist_ok=True)

            import subprocess
            import sys

            reqs = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze'])
            installed_packages = [r.decode().split('==')[0] for r in reqs.split()]

            if 'wget' in installed_packages:
                import wget
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'wget'])
                import wget

            if 'torch' in installed_packages:
                import torch.nn as nn
                import torch
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'torch==1.5.0',
                                '-f', 'https://download.pytorch.org/whl/torch_stable.html'])
                import torch.nn as nn
                import torch

            if 'torchvision' in installed_packages:
                import torchvision
                import torchvision.transforms as transforms
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'torchvision==0.6.0',
                                '-f', 'https://download.pytorch.org/whl/torch_stable.html'])
                import torchvision
                import torchvision.transforms as transforms

            import matplotlib.pyplot as plt
            import numpy as np
            import os

            try:
                from function_library.function_library import Net, imshow
            except:
                print("Installing function_library")
                url_function = 'https://raw.githubusercontent.com/pshah16/KubeflowNotebookPipelineDeployment/master/kale/examples/pytorch-classification/function_library/function_library.py'
                path = '/'
                wget.download(url_function, path)
                print("Function library installed")
                sys.path.append(path)
                import function_library
                print("Imported function_library")
                from function_library import Net, imshow
                print("Imported functions from function_library")
            classes = ('plane', 'car', 'bird', 'cat',
                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

            input_data_folder = "./data"

            transform = transforms.Compose(
                [transforms.ToTensor(),
                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

            trainset = torchvision.datasets.CIFAR10(root=input_data_folder, train=True,
                                                    download=True, transform=transform)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                                      shuffle=True, num_workers=2)

            testset = torchvision.datasets.CIFAR10(root=input_data_folder, train=False,
                                                   download=True, transform=transform)
            testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                                     shuffle=False, num_workers=2)

            # -----------------------DATA SAVING START---------------------------------
            if "testloader" in locals():
                _kale_resource_save(testloader, os.path.join(
                    _kale_data_directory, "testloader"))
            else:
                print("_kale_resource_save: `testloader` not found.")
            if "trainloader" in locals():
                _kale_resource_save(trainloader, os.path.join(
                    _kale_data_directory, "trainloader"))
            else:
                print("_kale_resource_save: `trainloader` not found.")

        import argparse
        _parser = argparse.ArgumentParser(prog='Dataprocessing', description='')
        _parser.add_argument("--TRAIN-STEPS", dest="TRAIN_STEPS", type=int, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = dataprocessing(**_parsed_args)

        if not hasattr(_outputs, '__getitem__') or isinstance(_outputs, str):
            _outputs = [_outputs]

        _output_serializers = [

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        auroradevacr.azurecr.io/kubeflownotebook
      "resources":
        "limits":
          "cpu": |-
            0.5
          "memory": |-
            4G
        "requests":
          "cpu": |-
            0.5
          "memory": |-
            2G
      "securityContext":
        "runAsUser": !!int |-
          0
      "volumeMounts":
      - "mountPath": |-
          /marshal
        "name": |-
          kale-marshal-volume
      "workingDir": |-
        /home/jovyan/data-vol-1/KubeflowNotebookPipelineDeployment/kale/examples/pytorch-classification
    "inputs":
      "parameters":
      - "name": |-
          TRAIN_STEPS
      - "name": |-
          kale-marshal-volume-name
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "TRAIN_STEPS", "type": "Integer"}], "name": "Dataprocessing"}
    "name": |-
      dataprocessing
    "volumes":
    - "name": |-
        kale-marshal-volume
      "persistentVolumeClaim":
        "claimName": |-
          {{inputs.parameters.kale-marshal-volume-name}}
  - "name": |-
      kale-marshal-volume
    "outputs":
      "parameters":
      - "name": |-
          kale-marshal-volume-manifest
        "valueFrom":
          "jsonPath": |-
            {}
      - "name": |-
          kale-marshal-volume-name
        "valueFrom":
          "jsonPath": |-
            {.metadata.name}
      - "name": |-
          kale-marshal-volume-size
        "valueFrom":
          "jsonPath": |-
            {.status.capacity.storage}
    "resource":
      "action": |-
        create
      "manifest": |
        apiVersion: v1
        kind: PersistentVolumeClaim
        metadata:
          annotations:
            example: cifar_pvc
          name: '{{workflow.name}}-kale-marshal-pvc'
        spec:
          accessModes:
          - ReadWriteMany
          resources:
            requests:
              storage: 2Gi
          storageClassName: standard
  - "container":
      "args":
      - |-
        --TRAIN-STEPS
      - |-
        {{inputs.parameters.TRAIN_STEPS}}
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def testontest(TRAIN_STEPS: int):

            import os
            import shutil
            from kale.utils import pod_utils
            from kale.marshal import resource_save as _kale_resource_save
            from kale.marshal import resource_load as _kale_resource_load

            _kale_data_directory = "/marshal"

            if not os.path.isdir(_kale_data_directory):
                os.makedirs(_kale_data_directory, exist_ok=True)

            # -----------------------DATA LOADING START--------------------------------
            _kale_directory_file_names = [
                os.path.splitext(f)[0]
                for f in os.listdir(_kale_data_directory)
                if os.path.isfile(os.path.join(_kale_data_directory, f))
            ]

            if "net" not in _kale_directory_file_names:
                raise ValueError("net" + " does not exists in directory")

            _kale_load_file_name = [
                f
                for f in os.listdir(_kale_data_directory)
                if os.path.isfile(os.path.join(_kale_data_directory, f)) and
                os.path.splitext(f)[0] == "net"
            ]
            if len(_kale_load_file_name) > 1:
                raise ValueError("Found multiple files with name " +
                                 "net" + ": " + str(_kale_load_file_name))
            _kale_load_file_name = _kale_load_file_name[0]
            net = _kale_resource_load(os.path.join(
                _kale_data_directory, _kale_load_file_name))

            if "testloader" not in _kale_directory_file_names:
                raise ValueError("testloader" + " does not exists in directory")

            _kale_load_file_name = [
                f
                for f in os.listdir(_kale_data_directory)
                if os.path.isfile(os.path.join(_kale_data_directory, f)) and
                os.path.splitext(f)[0] == "testloader"
            ]
            if len(_kale_load_file_name) > 1:
                raise ValueError("Found multiple files with name " +
                                 "testloader" + ": " + str(_kale_load_file_name))
            _kale_load_file_name = _kale_load_file_name[0]
            testloader = _kale_resource_load(os.path.join(
                _kale_data_directory, _kale_load_file_name))
            # -----------------------DATA LOADING END----------------------------------

            import subprocess
            import sys

            reqs = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze'])
            installed_packages = [r.decode().split('==')[0] for r in reqs.split()]

            if 'wget' in installed_packages:
                import wget
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'wget'])
                import wget

            if 'torch' in installed_packages:
                import torch.nn as nn
                import torch
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'torch==1.5.0',
                                '-f', 'https://download.pytorch.org/whl/torch_stable.html'])
                import torch.nn as nn
                import torch

            if 'torchvision' in installed_packages:
                import torchvision
                import torchvision.transforms as transforms
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'torchvision==0.6.0',
                                '-f', 'https://download.pytorch.org/whl/torch_stable.html'])
                import torchvision
                import torchvision.transforms as transforms

            import matplotlib.pyplot as plt
            import numpy as np
            import os

            try:
                from function_library.function_library import Net, imshow
            except:
                print("Installing function_library")
                url_function = 'https://raw.githubusercontent.com/pshah16/KubeflowNotebookPipelineDeployment/master/kale/examples/pytorch-classification/function_library/function_library.py'
                path = '/'
                wget.download(url_function, path)
                print("Function library installed")
                sys.path.append(path)
                import function_library
                print("Imported function_library")
                from function_library import Net, imshow
                print("Imported functions from function_library")
            classes = ('plane', 'car', 'bird', 'cat',
                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

            dataiter = iter(testloader)
            images, labels = dataiter.next()

            # print images
            imshow(torchvision.utils.make_grid(images))
            print('GroundTruth: ', ' '.join('%5s' %
                                            classes[labels[j]] for j in range(4)))
            outputs = net(images)
            _, predicted = torch.max(outputs, 1)

            print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]
                                          for j in range(4)))

            # -----------------------DATA SAVING START---------------------------------
            if "net" in locals():
                _kale_resource_save(net, os.path.join(_kale_data_directory, "net"))
            else:
                print("_kale_resource_save: `net` not found.")
            if "testloader" in locals():
                _kale_resource_save(testloader, os.path.join(
                    _kale_data_directory, "testloader"))
            else:
                print("_kale_resource_save: `testloader` not found.")

        import argparse
        _parser = argparse.ArgumentParser(prog='Testontest', description='')
        _parser.add_argument("--TRAIN-STEPS", dest="TRAIN_STEPS", type=int, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = testontest(**_parsed_args)

        if not hasattr(_outputs, '__getitem__') or isinstance(_outputs, str):
            _outputs = [_outputs]

        _output_serializers = [

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        auroradevacr.azurecr.io/kubeflownotebook
      "resources":
        "limits":
          "cpu": |-
            0.5
          "memory": |-
            4G
        "requests":
          "cpu": |-
            0.5
          "memory": |-
            2G
      "securityContext":
        "runAsUser": !!int |-
          0
      "volumeMounts":
      - "mountPath": |-
          /marshal
        "name": |-
          kale-marshal-volume
      "workingDir": |-
        /home/jovyan/data-vol-1/KubeflowNotebookPipelineDeployment/kale/examples/pytorch-classification
    "inputs":
      "parameters":
      - "name": |-
          TRAIN_STEPS
      - "name": |-
          kale-marshal-volume-name
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "TRAIN_STEPS", "type": "Integer"}], "name": "Testontest"}
    "name": |-
      testontest
    "volumes":
    - "name": |-
        kale-marshal-volume
      "persistentVolumeClaim":
        "claimName": |-
          {{inputs.parameters.kale-marshal-volume-name}}
  - "container":
      "args":
      - |-
        --TRAIN-STEPS
      - |-
        {{inputs.parameters.TRAIN_STEPS}}
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def testwhole(TRAIN_STEPS: int):

            import os
            import shutil
            from kale.utils import pod_utils
            from kale.marshal import resource_save as _kale_resource_save
            from kale.marshal import resource_load as _kale_resource_load

            _kale_data_directory = "/marshal"

            if not os.path.isdir(_kale_data_directory):
                os.makedirs(_kale_data_directory, exist_ok=True)

            # -----------------------DATA LOADING START--------------------------------
            _kale_directory_file_names = [
                os.path.splitext(f)[0]
                for f in os.listdir(_kale_data_directory)
                if os.path.isfile(os.path.join(_kale_data_directory, f))
            ]

            if "net" not in _kale_directory_file_names:
                raise ValueError("net" + " does not exists in directory")

            _kale_load_file_name = [
                f
                for f in os.listdir(_kale_data_directory)
                if os.path.isfile(os.path.join(_kale_data_directory, f)) and
                os.path.splitext(f)[0] == "net"
            ]
            if len(_kale_load_file_name) > 1:
                raise ValueError("Found multiple files with name " +
                                 "net" + ": " + str(_kale_load_file_name))
            _kale_load_file_name = _kale_load_file_name[0]
            net = _kale_resource_load(os.path.join(
                _kale_data_directory, _kale_load_file_name))

            if "testloader" not in _kale_directory_file_names:
                raise ValueError("testloader" + " does not exists in directory")

            _kale_load_file_name = [
                f
                for f in os.listdir(_kale_data_directory)
                if os.path.isfile(os.path.join(_kale_data_directory, f)) and
                os.path.splitext(f)[0] == "testloader"
            ]
            if len(_kale_load_file_name) > 1:
                raise ValueError("Found multiple files with name " +
                                 "testloader" + ": " + str(_kale_load_file_name))
            _kale_load_file_name = _kale_load_file_name[0]
            testloader = _kale_resource_load(os.path.join(
                _kale_data_directory, _kale_load_file_name))
            # -----------------------DATA LOADING END----------------------------------

            import subprocess
            import sys

            reqs = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze'])
            installed_packages = [r.decode().split('==')[0] for r in reqs.split()]

            if 'wget' in installed_packages:
                import wget
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'wget'])
                import wget

            if 'torch' in installed_packages:
                import torch.nn as nn
                import torch
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'torch==1.5.0',
                                '-f', 'https://download.pytorch.org/whl/torch_stable.html'])
                import torch.nn as nn
                import torch

            if 'torchvision' in installed_packages:
                import torchvision
                import torchvision.transforms as transforms
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'torchvision==0.6.0',
                                '-f', 'https://download.pytorch.org/whl/torch_stable.html'])
                import torchvision
                import torchvision.transforms as transforms

            import matplotlib.pyplot as plt
            import numpy as np
            import os

            try:
                from function_library.function_library import Net, imshow
            except:
                print("Installing function_library")
                url_function = 'https://raw.githubusercontent.com/pshah16/KubeflowNotebookPipelineDeployment/master/kale/examples/pytorch-classification/function_library/function_library.py'
                path = '/'
                wget.download(url_function, path)
                print("Function library installed")
                sys.path.append(path)
                import function_library
                print("Imported function_library")
                from function_library import Net, imshow
                print("Imported functions from function_library")
            classes = ('plane', 'car', 'bird', 'cat',
                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

            correct = 0
            total = 0
            with torch.no_grad():
                for data in testloader:
                    images, labels = data
                    outputs = net(images)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

            print('Accuracy of the network on the 10000 test images: %d %%' % (
                100 * correct / total))
            class_correct = list(0. for i in range(10))
            class_total = list(0. for i in range(10))
            with torch.no_grad():
                for data in testloader:
                    images, labels = data
                    outputs = net(images)
                    _, predicted = torch.max(outputs, 1)
                    c = (predicted == labels).squeeze()
                    for i in range(4):
                        label = labels[i]
                        class_correct[label] += c[i].item()
                        class_total[label] += 1

            for i in range(10):
                print('Accuracy of %5s : %2d %%' % (
                    classes[i], 100 * class_correct[i] / class_total[i]))

        import argparse
        _parser = argparse.ArgumentParser(prog='Testwhole', description='')
        _parser.add_argument("--TRAIN-STEPS", dest="TRAIN_STEPS", type=int, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = testwhole(**_parsed_args)

        if not hasattr(_outputs, '__getitem__') or isinstance(_outputs, str):
            _outputs = [_outputs]

        _output_serializers = [

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        auroradevacr.azurecr.io/kubeflownotebook
      "resources":
        "limits":
          "cpu": |-
            0.5
          "memory": |-
            4G
        "requests":
          "cpu": |-
            0.5
          "memory": |-
            2G
      "securityContext":
        "runAsUser": !!int |-
          0
      "volumeMounts":
      - "mountPath": |-
          /marshal
        "name": |-
          kale-marshal-volume
      "workingDir": |-
        /home/jovyan/data-vol-1/KubeflowNotebookPipelineDeployment/kale/examples/pytorch-classification
    "inputs":
      "parameters":
      - "name": |-
          TRAIN_STEPS
      - "name": |-
          kale-marshal-volume-name
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "TRAIN_STEPS", "type": "Integer"}], "name": "Testwhole"}
    "name": |-
      testwhole
    "volumes":
    - "name": |-
        kale-marshal-volume
      "persistentVolumeClaim":
        "claimName": |-
          {{inputs.parameters.kale-marshal-volume-name}}
  - "container":
      "args":
      - |-
        --TRAIN-STEPS
      - |-
        {{inputs.parameters.TRAIN_STEPS}}
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def train(TRAIN_STEPS: int):

            import os
            import shutil
            from kale.utils import pod_utils
            from kale.marshal import resource_save as _kale_resource_save
            from kale.marshal import resource_load as _kale_resource_load

            _kale_data_directory = "/marshal"

            if not os.path.isdir(_kale_data_directory):
                os.makedirs(_kale_data_directory, exist_ok=True)

            # -----------------------DATA LOADING START--------------------------------
            _kale_directory_file_names = [
                os.path.splitext(f)[0]
                for f in os.listdir(_kale_data_directory)
                if os.path.isfile(os.path.join(_kale_data_directory, f))
            ]

            if "trainloader" not in _kale_directory_file_names:
                print("_kale_directory_file_names: {}".format(_kale_directory_file_names))
                raise ValueError("trainloader" + " does not exists in directory")

            _kale_load_file_name = [
                f
                for f in os.listdir(_kale_data_directory)
                if os.path.isfile(os.path.join(_kale_data_directory, f)) and
                os.path.splitext(f)[0] == "trainloader"
            ]
            if len(_kale_load_file_name) > 1:
                raise ValueError("Found multiple files with name " +
                                 "trainloader" + ": " + str(_kale_load_file_name))
            _kale_load_file_name = _kale_load_file_name[0]
            trainloader = _kale_resource_load(os.path.join(
                _kale_data_directory, _kale_load_file_name))
            # -----------------------DATA LOADING END----------------------------------

            import subprocess
            import sys

            reqs = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze'])
            installed_packages = [r.decode().split('==')[0] for r in reqs.split()]

            if 'wget' in installed_packages:
                import wget
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'wget'])
                import wget

            if 'torch' in installed_packages:
                import torch.nn as nn
                import torch
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'torch==1.5.0',
                                '-f', 'https://download.pytorch.org/whl/torch_stable.html'])
                import torch.nn as nn
                import torch

            if 'torchvision' in installed_packages:
                import torchvision
                import torchvision.transforms as transforms
            else:
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'torchvision==0.6.0',
                                '-f', 'https://download.pytorch.org/whl/torch_stable.html'])
                import torchvision
                import torchvision.transforms as transforms

            import matplotlib.pyplot as plt
            import numpy as np
            import os

            try:
                from function_library.function_library import Net, imshow
            except:
                print("Installing function_library")
                url_function = 'https://raw.githubusercontent.com/pshah16/KubeflowNotebookPipelineDeployment/master/kale/examples/pytorch-classification/function_library/function_library.py'
                path = '/'
                wget.download(url_function, path)
                print("Function library installed")
                sys.path.append(path)
                import function_library
                print("Imported function_library")
                from function_library import Net, imshow
                print("Imported functions from function_library")
            classes = ('plane', 'car', 'bird', 'cat',
                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

            import torch.optim as optim

            net = Net()
            criterion = nn.CrossEntropyLoss()
            optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
            for epoch in range(TRAIN_STEPS):  # loop over the dataset multiple times

                running_loss = 0.0
                for i, data in enumerate(trainloader, 0):
                    # get the inputs
                    inputs, labels = data

                    # zero the parameter gradients
                    optimizer.zero_grad()

                    # forward + backward + optimize
                    outputs = net(inputs)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    optimizer.step()

                    # print statistics
                    running_loss += loss.item()
                    if i % 2000 == 1999:    # print every 2000 mini-batches
                        print('[%d, %5d] loss: %.3f' %
                              (epoch + 1, i + 1, running_loss / 2000))
                        running_loss = 0.0

            print('Finished Training')

            # -----------------------DATA SAVING START---------------------------------
            if "net" in locals():
                _kale_resource_save(net, os.path.join(_kale_data_directory, "net"))
            else:
                print("_kale_resource_save: `net` not found.")

        import argparse
        _parser = argparse.ArgumentParser(prog='Train', description='')
        _parser.add_argument("--TRAIN-STEPS", dest="TRAIN_STEPS", type=int, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = train(**_parsed_args)

        if not hasattr(_outputs, '__getitem__') or isinstance(_outputs, str):
            _outputs = [_outputs]

        _output_serializers = [

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        auroradevacr.azurecr.io/kubeflownotebook
      "resources":
        "limits":
          "cpu": |-
            0.5
          "memory": |-
            4G
        "requests":
          "cpu": |-
            0.5
          "memory": |-
            2G
      "securityContext":
        "runAsUser": !!int |-
          0
      "volumeMounts":
      - "mountPath": |-
          /marshal
        "name": |-
          kale-marshal-volume
      "workingDir": |-
        /home/jovyan/data-vol-1/KubeflowNotebookPipelineDeployment/kale/examples/pytorch-classification
    "inputs":
      "parameters":
      - "name": |-
          TRAIN_STEPS
      - "name": |-
          kale-marshal-volume-name
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "TRAIN_STEPS", "type": "Integer"}], "name": "Train"}
    "name": |-
      train
    "volumes":
    - "name": |-
        kale-marshal-volume
      "persistentVolumeClaim":
        "claimName": |-
          {{inputs.parameters.kale-marshal-volume-name}}
